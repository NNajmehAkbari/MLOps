{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "188901c7-44b1-4513-bff0-36d7f7d3cc11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b8d091e6-b343-4b7b-beb8-e8de0112d1c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d8936860-1eea-48fe-af84-eca27fb8091c/lib/python3.12/site-packages (2.0.0)\nRequirement already satisfied: bleach in /databricks/python3/lib/python3.12/site-packages (from kaggle) (6.2.0)\nRequirement already satisfied: kagglesdk<1.0,>=0.1.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d8936860-1eea-48fe-af84-eca27fb8091c/lib/python3.12/site-packages (from kaggle) (0.1.15)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from kaggle) (24.1)\nRequirement already satisfied: protobuf in /databricks/python3/lib/python3.12/site-packages (from kaggle) (5.29.4)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d8936860-1eea-48fe-af84-eca27fb8091c/lib/python3.12/site-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from kaggle) (2.32.3)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d8936860-1eea-48fe-af84-eca27fb8091c/lib/python3.12/site-packages (from kaggle) (4.67.3)\nRequirement already satisfied: urllib3>=1.15.1 in /databricks/python3/lib/python3.12/site-packages (from kaggle) (2.3.0)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil->kaggle) (1.16.0)\nRequirement already satisfied: text-unidecode>=1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d8936860-1eea-48fe-af84-eca27fb8091c/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->kaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->kaggle) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->kaggle) (2025.1.31)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4d54289-31bb-41b8-9b48-bcfce8275bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a hidden text input box at the top of the notebook\n",
    "dbutils.widgets.text(\"kaggle_key_input\", \"\", \"Enter Kaggle Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c4a3ac8-41ef-4666-aba7-8455ff7bf12e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle is settled!\n"
     ]
    }
   ],
   "source": [
    "# Get the value from the widget\n",
    "secret_key = dbutils.widgets.get(\"kaggle_key_input\")\n",
    "os.environ['KAGGLE_KEY'] = secret_key\n",
    "print(\"Kaggle is settled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efc760b6-1895-4f77-bda5-cf6061346ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data\nLicense(s): CC0-1.0\nDownloading daily-climate-time-series-data.zip to /Workspace/Users/n.najmehakbari@gmail.com/Drafts\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0.00/22.0k [00:00<?, ?B/s]\r100%|██████████| 22.0k/22.0k [00:00<00:00, 9.18MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CompletedProcess(args=['kaggle', 'datasets', 'download', '-d', 'sumanthvrao/daily-climate-time-series-data', '--unzip'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['kaggle', 'datasets', 'download', '-d', 'sumanthvrao/daily-climate-time-series-data', '--unzip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe008d6-96aa-48a8-917a-d8483d329663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into Spark via Pandas!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date</th><th>meantemp</th><th>humidity</th><th>wind_speed</th><th>meanpressure</th></tr></thead><tbody><tr><td>2013-01-01</td><td>10.0</td><td>84.5</td><td>0.0</td><td>1015.6666666666666</td></tr><tr><td>2013-01-02</td><td>7.4</td><td>92.0</td><td>2.98</td><td>1017.8</td></tr><tr><td>2013-01-03</td><td>7.166666666666667</td><td>87.0</td><td>4.633333333333334</td><td>1018.6666666666666</td></tr><tr><td>2013-01-04</td><td>8.666666666666666</td><td>71.33333333333333</td><td>1.2333333333333334</td><td>1017.1666666666666</td></tr><tr><td>2013-01-05</td><td>6.0</td><td>86.83333333333333</td><td>3.7</td><td>1016.5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2013-01-01",
         10.0,
         84.5,
         0.0,
         1015.6666666666666
        ],
        [
         "2013-01-02",
         7.4,
         92.0,
         2.98,
         1017.8
        ],
        [
         "2013-01-03",
         7.166666666666667,
         87.0,
         4.633333333333334,
         1018.6666666666666
        ],
        [
         "2013-01-04",
         8.666666666666666,
         71.33333333333333,
         1.2333333333333334,
         1017.1666666666666
        ],
        [
         "2013-01-05",
         6.0,
         86.83333333333333,
         3.7,
         1016.5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "meantemp",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "humidity",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "wind_speed",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "meanpressure",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "local_path = f\"{os.getcwd()}/DailyDelhiClimateTrain.csv\"\n",
    "pdf = pd.read_csv(local_path)\n",
    "\n",
    "# Pandas DataFrame to Spark DataFrame\n",
    "df_all = spark.createDataFrame(pdf)\n",
    "df_all = df_all.orderBy(\"date\")\n",
    "\n",
    "print(\"Data successfully loaded into Spark via Pandas!\")\n",
    "display(df_all.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55b8092b-b179-4309-9d81-aff1c233e158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 ingested into Bronze layer.\nBatch 2 ingested into Bronze layer.\nBatch 3 ingested into Bronze layer.\nBatch 4 ingested into Bronze layer.\nBatch 5 ingested into Bronze layer.\n"
     ]
    }
   ],
   "source": [
    "total_rows = df_all.count()\n",
    "chunk_size = total_rows // 5\n",
    "\n",
    "for i in range(5):\n",
    "    start = i * chunk_size\n",
    "    limit_val = (i + 1) * chunk_size if i < 4 else total_rows\n",
    "    \n",
    "    # Create a Spark DataFrame for the current batch\n",
    "    current_batch = df_all.limit(limit_val).tail(limit_val - start)\n",
    "    batch_spark = spark.createDataFrame(current_batch, df_all.schema)\n",
    "    \n",
    "    # Bronze layer ingestion\n",
    "    batch_spark.write.format(\"delta\").mode(\"append\").saveAsTable(\"weather_bronze\")\n",
    "    print(f\"Batch {i+1} ingested into Bronze layer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4464a5-abf9-4e08-95bd-2d004cbc40e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from Bronze layer\n",
    "bronze_df = spark.read.table(\"weather_bronze\")\n",
    "\n",
    "# Silver layer ingestion \n",
    "silver_df = bronze_df.dropDuplicates([\"date\"]).dropna()\n",
    "\n",
    "# Remove outliers from meantemp column in Silver layer\n",
    "silver_df = silver_df.filter((col(\"meantemp\") > -20) & (col(\"meantemp\") < 60))\n",
    "\n",
    "# Write to Silver layer\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"weather_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6273ed9b-6f1a-47ec-b625-c6b2b50abd07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold table created successfully!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "# Read from Silver layer\n",
    "silver_df = spark.read.table(\"weather_silver\")\n",
    "\n",
    "# Define a window specification\n",
    "windowSpec = Window.orderBy(\"date\")\n",
    "\n",
    "# Gold layer ingestion(Feature Engineering)\n",
    "gold_df = silver_df.withColumn(\"prev_day_temp\", lag(\"meantemp\", 1).over(windowSpec))\n",
    "\n",
    "#  Remove rows with null values\n",
    "gold_df = gold_df.select(\"date\", \"prev_day_temp\", \"meantemp\").dropna()\n",
    "\n",
    "# Write to Gold layer \n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"weather_gold\")\n",
    "\n",
    "print(\"Gold table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67535eea-9fda-46fd-95b6-6407aa61383a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>queryHistoryStatementId</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>19</td><td>2026-02-14T13:11:38.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>bdae819e-5f61-4fad-a732-85ad6826b9e8</td><td>0214-131041-o32588r7-v2n</td><td>18</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 294, numOutputBytes -> 9549)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>18</td><td>2026-02-14T13:11:34.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>b2661235-e66f-4b08-9cfb-dd02854d4293</td><td>0214-131041-o32588r7-v2n</td><td>17</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7907)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>17</td><td>2026-02-14T13:11:31.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>d251affb-c459-4681-9b70-7f4063736b96</td><td>0214-131041-o32588r7-v2n</td><td>16</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7226)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>16</td><td>2026-02-14T13:11:28.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>daf13785-6086-4ac5-94e1-488385596f88</td><td>0214-131041-o32588r7-v2n</td><td>15</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7592)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>15</td><td>2026-02-14T13:11:24.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>456777b4-1f00-4d40-ba8a-ab1b85483477</td><td>0214-131041-o32588r7-v2n</td><td>14</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 8288)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>14</td><td>2026-02-13T21:08:16.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>d88d7225-fc19-49c2-9939-1bce4748cb07</td><td>0213-210635-16sj3sfp-v2n</td><td>13</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 294, numOutputBytes -> 9549)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>13</td><td>2026-02-13T21:08:13.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>3850ce70-1af5-46a7-b0fa-e705bc48d269</td><td>0213-210635-16sj3sfp-v2n</td><td>12</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7907)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>12</td><td>2026-02-13T21:08:10.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>06caafa3-1d52-43c3-a086-4f3ec0893869</td><td>0213-210635-16sj3sfp-v2n</td><td>11</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7226)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>11</td><td>2026-02-13T21:08:07.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>8ab482a6-b830-481a-b12b-589cd218fd4a</td><td>0213-210635-16sj3sfp-v2n</td><td>10</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7592)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>10</td><td>2026-02-13T21:08:04.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>c230d9d5-1c9f-4a24-ab01-404000841953</td><td>0213-210635-16sj3sfp-v2n</td><td>9</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 8288)</td><td>null</td><td>Databricks-Runtime/18.0.x-aarch64-photon-scala2.13</td></tr><tr><td>9</td><td>2026-02-10T21:56:12.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>8</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 294, numOutputBytes -> 9549)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>8</td><td>2026-02-10T21:56:10.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>7</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7907)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>7</td><td>2026-02-10T21:56:08.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>6</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7226)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>6</td><td>2026-02-10T21:56:06.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>5</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7592)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>5</td><td>2026-02-10T21:56:04.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>4</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 8288)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>4</td><td>2026-02-10T21:48:44.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 294, numOutputBytes -> 9549)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>3</td><td>2026-02-10T21:48:42.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>2</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7907)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>2</td><td>2026-02-10T21:48:39.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> true, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>1</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7226)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>1</td><td>2026-02-10T21:48:37.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>0</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 7592)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr><tr><td>0</td><td>2026-02-10T21:48:35.000Z</td><td>71445245683791</td><td>n.najmehakbari@gmail.com</td><td>CREATE TABLE AS SELECT</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.enableDeletionVectors\":\"true\"}, statsOnLoad -> true)</td><td>null</td><td>List(2199524748115638)</td><td>null</td><td>0210-214128-2adgjkrl-v2n</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 292, numOutputBytes -> 8288)</td><td>null</td><td>Databricks-Runtime/17.3.x-aarch64-photon-scala2.13</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         19,
         "2026-02-14T13:11:38.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "bdae819e-5f61-4fad-a732-85ad6826b9e8",
         "0214-131041-o32588r7-v2n",
         18,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "9549",
          "numOutputRows": "294"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         18,
         "2026-02-14T13:11:34.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "b2661235-e66f-4b08-9cfb-dd02854d4293",
         "0214-131041-o32588r7-v2n",
         17,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7907",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         17,
         "2026-02-14T13:11:31.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "d251affb-c459-4681-9b70-7f4063736b96",
         "0214-131041-o32588r7-v2n",
         16,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7226",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         16,
         "2026-02-14T13:11:28.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "daf13785-6086-4ac5-94e1-488385596f88",
         "0214-131041-o32588r7-v2n",
         15,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7592",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         15,
         "2026-02-14T13:11:24.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "456777b4-1f00-4d40-ba8a-ab1b85483477",
         "0214-131041-o32588r7-v2n",
         14,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "8288",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         14,
         "2026-02-13T21:08:16.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "d88d7225-fc19-49c2-9939-1bce4748cb07",
         "0213-210635-16sj3sfp-v2n",
         13,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "9549",
          "numOutputRows": "294"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         13,
         "2026-02-13T21:08:13.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "3850ce70-1af5-46a7-b0fa-e705bc48d269",
         "0213-210635-16sj3sfp-v2n",
         12,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7907",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         12,
         "2026-02-13T21:08:10.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "06caafa3-1d52-43c3-a086-4f3ec0893869",
         "0213-210635-16sj3sfp-v2n",
         11,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7226",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         11,
         "2026-02-13T21:08:07.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "8ab482a6-b830-481a-b12b-589cd218fd4a",
         "0213-210635-16sj3sfp-v2n",
         10,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7592",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         10,
         "2026-02-13T21:08:04.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         "c230d9d5-1c9f-4a24-ab01-404000841953",
         "0213-210635-16sj3sfp-v2n",
         9,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "8288",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/18.0.x-aarch64-photon-scala2.13"
        ],
        [
         9,
         "2026-02-10T21:56:12.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         8,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "9549",
          "numOutputRows": "294"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         8,
         "2026-02-10T21:56:10.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         7,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7907",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         7,
         "2026-02-10T21:56:08.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         6,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7226",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         6,
         "2026-02-10T21:56:06.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         5,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7592",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         5,
         "2026-02-10T21:56:04.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         4,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "8288",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         4,
         "2026-02-10T21:48:44.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "9549",
          "numOutputRows": "294"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         3,
         "2026-02-10T21:48:42.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         2,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7907",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         2,
         "2026-02-10T21:48:39.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         1,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7226",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         1,
         "2026-02-10T21:48:37.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         0,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "7592",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ],
        [
         0,
         "2026-02-10T21:48:35.000Z",
         "71445245683791",
         "n.najmehakbari@gmail.com",
         "CREATE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[]",
          "properties": "{\"delta.enableDeletionVectors\":\"true\"}",
          "statsOnLoad": "true"
         },
         null,
         [
          "2199524748115638"
         ],
         null,
         "0210-214128-2adgjkrl-v2n",
         null,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "8288",
          "numOutputRows": "292"
         },
         null,
         "Databricks-Runtime/17.3.x-aarch64-photon-scala2.13"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobRunId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "queryHistoryStatementId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 12
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"jobId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobName\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobRunId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"runId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"jobOwnerId\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"triggerType\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"notebookId\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "queryHistoryStatementId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY weather_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a99aa569-2af4-495b-b64d-a9bc7728b95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze Layer Shape: (5848, 5) -> (Rows, Columns)\nSilver Layer Shape: (1462, 5) -> (Data Quality applied)\nGold Layer Shape:   (1461, 3)   -> (Features engineered)\n\n--- Columns in Gold Layer ---\n['date', 'prev_day_temp', 'meantemp']\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "def get_spark_shape(df):\n",
    "    return (df.count(), len(df.columns))\n",
    "\n",
    "# Read from Bronze, Silver, and Gold layers\n",
    "bronze_df = spark.read.table(\"weather_bronze\")\n",
    "silver_df = spark.read.table(\"weather_silver\")\n",
    "gold_df = spark.read.table(\"weather_gold\")\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Bronze Layer Shape: {get_spark_shape(bronze_df)} -> (Rows, Columns)\")\n",
    "print(f\"Silver Layer Shape: {get_spark_shape(silver_df)} -> (Data Quality applied)\")\n",
    "print(f\"Gold Layer Shape:   {get_spark_shape(gold_df)}   -> (Features engineered)\")\n",
    "\n",
    "print(\"\\n--- Columns in Gold Layer ---\")\n",
    "print(gold_df.columns)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8934982810074906,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2026-02-10 23:38:18",
   "widgets": {
    "kaggle_key_input": {
     "currentValue": "\"KGAT_86ae9d7f12562a83a674b22f0a73cb9c\"",
     "nuid": "4bd24aef-5f12-4223-9c67-0a96f9de7d55",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter Kaggle Key",
      "name": "kaggle_key_input",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter Kaggle Key",
      "name": "kaggle_key_input",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}